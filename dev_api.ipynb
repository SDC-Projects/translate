{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c32116-d574-46d4-bacb-05715ea3b0ca",
   "metadata": {},
   "source": [
    "# Programa de Especialización en Procesamiento de Lenguaje Natural (NLP) \n",
    "## Tema: Procesamiento de Lenguaje Multilingüe y Traducción\n",
    "\n",
    "#### Manuel Sigüeñas, M.Sc.(c)\n",
    "#### Prof. Inteligencia artificial & Ciencia de Datos\n",
    "[msiguenas@sdc-consulting-ti.com](msiguenas@sdc-consulting-ti.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c04b7-bd84-48bd-83c5-b92f1e7a2ca9",
   "metadata": {},
   "source": [
    "### Desafíos del procesamiento de lenguaje multilingüe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2797b6-98ab-49fb-8116-2509f609f039",
   "metadata": {},
   "source": [
    "Variabilidad morfológica y sintáctica: lenguas como el alemán o el chino presentan desafíos en la segmentación y estructura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44486c78-e8c7-4ab8-9555-2923f67fe332",
   "metadata": {},
   "source": [
    "Idiomas con recursos limitados: falta de datos de entrenamiento para muchos idiomas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94343896-6e00-46de-b0f9-3fb4d3d7a67d",
   "metadata": {},
   "source": [
    "Polisemia y contexto: palabras con múltiples significados según el idioma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da7ff4-d04f-43f3-87ae-aa5ad490e876",
   "metadata": {},
   "source": [
    "### Modelos de Traducción Automática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f327c1-72aa-4cc3-8205-5e9a51624e38",
   "metadata": {},
   "source": [
    "**MarianMT para traducción multilingüe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e383910-20af-45d7-8dd7-13d54a8df338",
   "metadata": {},
   "source": [
    "Evolución de los modelos de traducción automática:\n",
    "\n",
    "    - Modelos estadísticos basados en alineación de frases.\n",
    "    - Modelos neuronales basados en RNN y GRU: avances y limitaciones.\n",
    "    - Transformers: introducción a la atención y autoatención.\n",
    "\n",
    "Modelos modernos:\n",
    "\n",
    "    - MarianMT para traducción multilingüe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1086cc8-7ed3-4875-8080-7049e5671092",
   "metadata": {},
   "source": [
    "URL: https://huggingface.co/Helsinki-NLP/opus-mt-en-es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a7ef8-5293-4bde-899c-8dcf3d06334c",
   "metadata": {},
   "source": [
    "- Instalar Sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f038be3c-d002-42cf-bed7-b46b24fb3b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/991.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 71.7/991.5 kB 777.7 kB/s eta 0:00:02\n",
      "   --- ----------------------------------- 92.2/991.5 kB 581.0 kB/s eta 0:00:02\n",
      "   ----- -------------------------------- 153.6/991.5 kB 762.6 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 256.0/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 337.9/991.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 430.1/991.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 430.1/991.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 553.0/991.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 583.7/991.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 614.4/991.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 747.5/991.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 747.5/991.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 747.5/991.5 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 798.7/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 880.6/991.5 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 962.6/991.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/991.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6293ce0d-fbf3-41d8-887a-f69557c27407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.44.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d9d978-d7d3-4163-97df-75cebcd18e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98963719-b3b5-4a2c-a629-1aa28f96a5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOCIAL DATA\\.conda\\envs\\env_nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo preentrenado de traducción\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcddb009-044b-47c9-8756-3d8f6870fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traducción: ['Traducción automática es un campo fascinante.', '¿Cómo estás?']\n"
     ]
    }
   ],
   "source": [
    "# Texto a traducir\n",
    "text = [\"Machine translation is a fascinating field.\", \"How are you?\"]\n",
    "\n",
    "# Traducción\n",
    "inputs = tokenizer(text,\n",
    "                   return_tensors=\"pt\",\n",
    "                   padding=True,\n",
    "                   truncation=True)\n",
    "translated = model.generate(**inputs)\n",
    "translated_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "print(\"Traducción:\", translated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262811a-292f-4586-81ec-38f9abf26e7c",
   "metadata": {},
   "source": [
    "### Evaluación de Traducción Automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66125ed4-325a-4e78-9a8c-52105355a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b3dc24-0fa5-4fc4-b853-8decbda12f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traducción de referencia y generada\n",
    "reference = [\"La traducción automática es fascinante.\"]\n",
    "candidate = [\"La traducción automática es fascinante.\"]\n",
    "# Tokenización de las oraciones (listas de palabras)\n",
    "reference_tokenized = [ref.split() for ref in reference]\n",
    "candidate_tokenized = candidate[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bec8d05-b618-4f98-be8a-c888823ac2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['La', 'traducción', 'automática', 'es', 'fascinante.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307c498-d2bb-4dc9-8317-fda57d53d26b",
   "metadata": {},
   "source": [
    "**BLEU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e3ff5-88c0-427a-8d30-95c5966e49fc",
   "metadata": {},
   "source": [
    "Precisión de n-gramas entre la traducción generada y la referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87145c1f-b1c3-4c6e-9b54-f5b8d406cc52",
   "metadata": {},
   "source": [
    "1. BLEU (Bilingual Evaluation Understudy Score)\n",
    "Cómo funciona:\n",
    "\n",
    "    BLEU mide la precisión de n-gramas (grupos de palabras consecutivas) entre la traducción generada por la máquina y una o más traducciones de referencia.\n",
    "    Introduce un mecanismo de penalización llamado brevity penalty para evitar traducciones artificialmente cortas.\n",
    "    No considera el orden global o semántico, pero mide qué tan similares son los fragmentos (n-gramas) entre las traducciones.\n",
    "\n",
    "Valores que toma:\n",
    "\n",
    "    Rango: 0 a 1 (o 0 a 100 si se multiplica por 100).\n",
    "    1.0 significa una traducción idéntica a la referencia.\n",
    "    0.0 significa que no hay coincidencia en los n-gramas.\n",
    "    Generalmente, un BLEU > 0.3 (30%) se considera razonable para sistemas de traducción automática.\n",
    "    Valores intermedios: BLEU suele ser bajo en traducciones complejas o para lenguajes con grandes diferencias estructurales.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "    Es simple y fácil de implementar.\n",
    "    Es eficaz para medir la exactitud en traducciones cortas y técnicas.\n",
    "\n",
    "Limitaciones:\n",
    "\n",
    "    No considera sinónimos ni reordenamientos válidos en la estructura gramatical.\n",
    "    Tiende a penalizar traducciones creativas o aquellas que no coincidan exactamente con la referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e99d816c-1a21-4736-9f8c-31e2a72c630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Cálculo del BLEU Score\n",
    "bleu = sentence_bleu(reference_tokenized, candidate_tokenized)\n",
    "print(f\"BLEU Score: {bleu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7639f-f1e5-42fd-8387-c194a6e37812",
   "metadata": {},
   "source": [
    "**METEOR** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006ccf0-ba41-4874-9bc4-cad00627403b",
   "metadata": {},
   "source": [
    "Incluye análisis semántico y flexibilidad en sinónimos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe27e766-eac3-4511-a637-ce6e04d3e2ae",
   "metadata": {},
   "source": [
    "2. METEOR (Metric for Evaluation of Translation with Explicit ORdering)\n",
    "Cómo funciona:\n",
    "\n",
    "    METEOR evalúa la traducción basada en:\n",
    "    Precisión y Recall: ¿Cuántas palabras coinciden entre la traducción generada y la referencia?\n",
    "    Análisis semántico: Incluye sinónimos y lematización (identificación de raíces de palabras).\n",
    "    Flexibilidad estructural: Considera el reordenamiento de palabras si el significado se mantiene.\n",
    "    Combina estas métricas con una fórmula ponderada.\n",
    "\n",
    "Valores que toma:\n",
    "\n",
    "    Rango: 0 a 1 (o 0 a 100 si se multiplica por 100).\n",
    "    1.0 indica una coincidencia perfecta en precisión, recall y orden.\n",
    "    Valores cercanos a 0.0 indican una traducción muy diferente de la referencia.\n",
    "    Normalmente, METEOR tiene valores ligeramente más altos que BLEU porque es más flexible.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "    Más robusto que BLEU, ya que permite sinónimos y considera reordenamientos gramaticales.\n",
    "    Evalúa aspectos semánticos y no solo coincidencias exactas.\n",
    "\n",
    "Limitaciones:\n",
    "\n",
    "    Es más lento de calcular debido al análisis semántico.\n",
    "    Requiere recursos adicionales (por ejemplo, diccionarios de sinónimos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed31a5a-95ef-4143-bcfb-9b8598b668e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR Score: 0.996\n"
     ]
    }
   ],
   "source": [
    "# Cálculo del METEOR Score\n",
    "meteor = meteor_score(reference_tokenized, candidate_tokenized)\n",
    "print(f\"METEOR Score: {meteor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a05ed-b915-4008-b50d-98ecb8236428",
   "metadata": {},
   "source": [
    "### Aplicación Práctica: Implementación de un Modelo Básico de Traducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d237b9ac-e978-49fb-bebe-da0fd3391fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\social data\\.conda\\envs\\env_nlp\\lib\\site-packages (from sacremoses) (2024.7.24)\n",
      "Requirement already satisfied: click in c:\\users\\social data\\.conda\\envs\\env_nlp\\lib\\site-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\social data\\.conda\\envs\\env_nlp\\lib\\site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\social data\\.conda\\envs\\env_nlp\\lib\\site-packages (from sacremoses) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\social data\\.conda\\envs\\env_nlp\\lib\\site-packages (from click->sacremoses) (0.4.6)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "   ---------------------------------------- 0.0/897.5 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 143.4/897.5 kB 8.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 307.2/897.5 kB 4.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 337.9/897.5 kB 3.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 450.6/897.5 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 501.8/897.5 kB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 583.7/897.5 kB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 614.4/897.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 686.1/897.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 768.0/897.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/897.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 897.5/897.5 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66263d3d-28d7-4cf3-aee5-5c24727faafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "491dce93-3d74-4f7c-a032-31110f596133",
   "metadata": {},
   "source": [
    "**Despliegue del Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05d408-4f89-4aae-a5a0-2206eb6eb682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOCIAL DATA\\.conda\\envs\\env_nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Apr/2025 20:00:27] \"POST /translate HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from flask import Flask, request, jsonify\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Inicializar el modelo y el tokenizador\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Crear la aplicación Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Ruta principal para traducción\n",
    "@app.route(\"/translate\", methods=[\"POST\"])\n",
    "def translate():\n",
    "    # Obtener el texto del cuerpo de la solicitud\n",
    "    data = request.get_json()\n",
    "    text = data.get(\"text\", \"\")\n",
    "\n",
    "    # Verificar si el texto está presente\n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    # Tokenización y traducción\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # Devolver el texto traducido\n",
    "    return jsonify({\"translated_text\": translated_text})\n",
    "\n",
    "# Ejecutar la aplicación\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"127.0.0.1\", port=8000, debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6b80a-847a-45d0-beb2-0ecc612a0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://127.0.0.1:8000/translate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
